{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import PIL\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from tensorflow.keras.models import load_model\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get label list from directory\n",
    "def get_labels(root):\n",
    "    dataset_dir = root\n",
    "    labels =[]\n",
    "    for sub_folder in os.listdir(dataset_dir):\n",
    "        sub_folder_files = os.listdir(os.path.join(dataset_dir, sub_folder))\n",
    "        for i, filename in enumerate(sub_folder_files):\n",
    "            labels.append(filename)\n",
    "        break\n",
    "    return labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model(\"./models/model7.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33\n",
      "1/1 [==============================] - 0s 264ms/step\n",
      "16\n",
      "Image: borobudur (199).jpg - Predicted class: borobudur\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "16\n",
      "Image: borobudur (200).jpg - Predicted class: borobudur\n",
      "1/1 [==============================] - 0s 45ms/step\n",
      "16\n",
      "Image: martapura (65).jpg - Predicted class: martapura\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "16\n",
      "Image: monas (187).jpg - Predicted class: monas\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "16\n",
      "Image: monas (189).jpg - Predicted class: monas\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "16\n",
      "Image: monumen_lobar (37).jpg - Predicted class: monumen_mataram_metro\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "16\n",
      "Image: monumen_lobar (38).jpg - Predicted class: monumen_lobar\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "16\n",
      "Image: monumen_mataram_metro (59).jpg - Predicted class: monumen_mataram_metro\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "16\n",
      "Image: monumen_sd (82).jpg - Predicted class: monumen_selamat_datang\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "16\n",
      "Image: monumen_sd (86).jpg - Predicted class: monumen_selamat_datang\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "16\n",
      "Image: monumen_sd (92).jpg - Predicted class: monumen_selamat_datang\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "16\n",
      "Image: monumen_surabaya (159).jpg - Predicted class: monumen_surabaya\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "16\n",
      "Image: monumen_surabaya (160).jpg - Predicted class: monumen_surabaya\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "16\n",
      "Image: monumen_surabaya (175).jpg - Predicted class: monumen_surabaya\n",
      "1/1 [==============================] - 0s 22ms/step\n",
      "16\n",
      "Image: monumen_surabaya (176).jpg - Predicted class: monumen_surabaya\n",
      "1/1 [==============================] - 0s 21ms/step\n",
      "16\n",
      "Image: museum_tsunami (94).jpg - Predicted class: museum_tsunami\n",
      "1/1 [==============================] - 0s 23ms/step\n",
      "16\n",
      "Image: museum_tsunami (96).jpg - Predicted class: museum_tsunami\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "16\n",
      "Image: pantai_penyu (89).jpg - Predicted class: pantai_penyu\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "16\n",
      "Image: pantai_penyu (94).jpg - Predicted class: pantai_penyu\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "16\n",
      "Image: prambanan (148).jpg - Predicted class: prambanan\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "16\n",
      "Image: prambanan (153).jpg - Predicted class: prambanan\n",
      "1/1 [==============================] - 0s 33ms/step\n",
      "16\n",
      "Image: pura_suranadi (33).jpg - Predicted class: pura_suranadi\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "16\n",
      "Image: rumah_aceh (74).jpg - Predicted class: rumah_aceh\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "16\n",
      "Image: rumah_aceh (77).jpg - Predicted class: rumah_aceh\n",
      "1/1 [==============================] - 0s 29ms/step\n",
      "16\n",
      "Image: sarinah (16).jpg - Predicted class: sarinah_mall\n",
      "1/1 [==============================] - 0s 49ms/step\n",
      "16\n",
      "Image: sarinah (18).jpg - Predicted class: prambanan\n",
      "1/1 [==============================] - 0s 30ms/step\n",
      "16\n",
      "Image: soedirman (138).jpg - Predicted class: prambanan\n",
      "1/1 [==============================] - 0s 28ms/step\n",
      "16\n",
      "Image: soedirman (139).jpg - Predicted class: jendral_sudirman\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "16\n",
      "Image: soedirman (140).jpg - Predicted class: jendral_sudirman\n",
      "1/1 [==============================] - 0s 24ms/step\n",
      "16\n",
      "Image: taman_sangkreang (25).jpg - Predicted class: taman_sangkreang\n",
      "1/1 [==============================] - 0s 25ms/step\n",
      "16\n",
      "Image: taman_sangkreang (32).jpg - Predicted class: taman_sangkreang\n",
      "1/1 [==============================] - 0s 26ms/step\n",
      "16\n",
      "Image: tugu_jogja (132).jpg - Predicted class: tugu_jogja\n",
      "1/1 [==============================] - 0s 27ms/step\n",
      "16\n",
      "Image: tugu_jogja (135).jpg - Predicted class: tugu_jogja\n"
     ]
    }
   ],
   "source": [
    "test_labels = ['borobudur', 'borobudur', 'martapura', 'monas',\n",
    "               'monas', 'monumen_lobar', 'monumen_lobar', 'monumen_mataram_metro', 'monumen_selamat_datang',\n",
    "               'monumen_selamat_datang', 'monumen_selamat_datang', 'monumen_surabaya', 'monumen_surabaya',\n",
    "               'monumen_surabaya', 'monumen_surabaya', 'monumen_tsunami',\n",
    "               'monumen_tsunami', 'pantai_penyu', 'pantai_penyu', 'prambanan', 'prambanan',\n",
    "               'pura_suranadi', 'rumah_aceh', 'rumah_aceh', 'sarinah', 'sarinah', 'soedirman', 'soedirman', \n",
    "               'soedirman', 'taman_sangkreang', 'taman_sangkreang', 'tugu_jogja', 'tugu_jogja']\n",
    "print(len(test_labels))\n",
    "predicted_labels =[]\n",
    "\n",
    "test_images_dir = './tourism_destination_2/testing_image/'\n",
    "\n",
    "# List all image files in the directory\n",
    "image_files = os.listdir(test_images_dir)\n",
    "\n",
    "for image_file in image_files:\n",
    "    # Load and preprocess the image\n",
    "    image_path = os.path.join(test_images_dir, image_file)\n",
    "    image = PIL.Image.open(image_path)\n",
    "    image = image.resize((150, 150))  # Adjust the size according to your model's input shape\n",
    "    image = np.array(image) / 255.0  # Normalize the image\n",
    "    image = np.expand_dims(image, axis=0)  # Add a batch dimension\n",
    "\n",
    "    # Perform the prediction\n",
    "    prediction = model.predict(image)\n",
    "    predicted_class = np.argmax(prediction)\n",
    "\n",
    "    # Get the predicted class label\n",
    "    root = './tourism_destination_2/tourism_destination/'\n",
    "    class_labels = get_labels(root)  # Replace with your own class labels\n",
    "    print(len(class_labels))\n",
    "    predicted_label = class_labels[predicted_class]\n",
    "\n",
    "    # Print the predicted class for the current image\n",
    "    print(f\"Image: {image_file} - Predicted class: {predicted_label}\")\n",
    "\n",
    "    predicted_labels.append(predicted_label)\n",
    "\n",
    "# Convert the predicted labels to match the test_labels format\n",
    "predicted_labels = np.array(predicted_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.7575757575757576\n",
      "Total True Predictions:  25\n",
      "Total False Predictions:  8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['borobudur',\n",
       " 'jendral_sudirman',\n",
       " 'martapura',\n",
       " 'monas',\n",
       " 'monumen_lobar',\n",
       " 'monumen_mataram_metro',\n",
       " 'monumen_selamat_datang',\n",
       " 'monumen_surabaya',\n",
       " 'museum_tsunami',\n",
       " 'pantai_penyu',\n",
       " 'prambanan',\n",
       " 'pura_suranadi',\n",
       " 'rumah_aceh',\n",
       " 'sarinah_mall',\n",
       " 'taman_sangkreang',\n",
       " 'tugu_jogja']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# print accuracy testing\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Evaluate the predictions using accuracy\n",
    "accuracy = accuracy_score(test_labels, predicted_labels)\n",
    "print(\"Accuracy: \", accuracy)\n",
    "\n",
    "# Calculate the total number of true and false predictions\n",
    "total_true = sum(test_labels == predicted_labels)\n",
    "total_false = sum(test_labels != predicted_labels)\n",
    "\n",
    "print(\"Total True Predictions: \", total_true)\n",
    "print(\"Total False Predictions: \", total_false)\n",
    "\n",
    "test = get_labels(root)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import csv\n",
    "\n",
    "def save_labels_to_csv(labels, file_path):\n",
    "    with open(file_path, 'w', newline='') as csvfile:\n",
    "        writer = csv.writer(csvfile)\n",
    "        writer.writerow([\"Label\"])  # Writing the header row\n",
    "        for label in labels:\n",
    "            writer.writerow([label])\n",
    "\n",
    "labels = get_labels(root)\n",
    "save_labels_to_csv(labels, \"labels.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# add precision recall\n",
    "# confusion matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_2\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_8 (Conv2D)           (None, 148, 148, 32)      896       \n",
      "                                                                 \n",
      " max_pooling2d_8 (MaxPooling  (None, 74, 74, 32)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 72, 72, 64)        18496     \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 36, 36, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_10 (Conv2D)          (None, 34, 34, 128)       73856     \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 17, 17, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_11 (Conv2D)          (None, 15, 15, 128)       147584    \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 7, 7, 128)        0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " flatten_2 (Flatten)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dropout_2 (Dropout)         (None, 6272)              0         \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 512)               3211776   \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 16)                8208      \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,460,816\n",
      "Trainable params: 3,460,816\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
